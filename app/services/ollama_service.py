# ============================================================
# services/ollama_service.py - AI é›™éšæ®µæµæ°´ç·šæœå‹™
# å°ˆæ¡ˆï¼šChi Soo ç§Ÿå±‹å°å¹«æ‰‹
# èªªæ˜ï¼šå°è£ Ollama API èª¿ç”¨
# ============================================================

import json
import requests
from typing import Optional

from app.config import config


class OllamaService:
    """
    Ollama AI é›™éšæ®µæµæ°´ç·šæœå‹™
    
    å¯¦ä½œè¨­è¨ˆæ–‡ä»¶ä¸­çš„é›™éšæ®µè™•ç†ï¼š
    1. Stage 1 : å¾ä½¿ç”¨è€…å°è©±ä¸­æå–æ¨™ç±¤èˆ‡åƒæ•¸
    2. Stage 2 : ç¢ºèªè³‡æ–™å®Œæ•´æ€§ä¸¦ç”Ÿæˆè¿½å•èªå¥
    """
    
    # å¿…è¦æª¢æŸ¥æ¸…å–® - æ ¹æ“šæ¼”ç®—æ³•æ–‡ä»¶çš„å…­å¤§ç¶­åº¦ (é—œéµå­—ç‚ºéš±æ€§ç¶­åº¦ï¼Œä¸é ˆè©¢å•)
    # 1. é ç®— (budget)
    # 2. åœ°é» (location_pref)
    # 3. æˆ¿å‹ (type_pref)
    # 4. ç®¡ç†åå¥½ (management_pref)
    # 5. è¨­æ–½éœ€æ±‚ (features_preference) - ç¢ºèªä½¿ç”¨è€…æ˜¯å¦æœ‰ä¸€å¾—å¿…æœ‰çš„è¨­æ–½
    REQUIRED_FIELDS = ["budget", "location_pref", "type_pref", "management_pref", "features_preference"]
    
    # å¯é¸æ¬„ä½ - è¨­æ–½éœ€æ±‚ (è‡ªç”±æ–‡å­—é™£åˆ—)
    OPTIONAL_FIELDS = ["required_features"]
    
    # è¿½å•å•é¡Œåº«
    QUESTIONS = {
        "budget": (
            "ğŸ’° é¦–å…ˆï¼Œè«‹å•æ‚¨çš„ æœˆç§Ÿé ç®—ä¸Šé™ å¤§ç´„æ˜¯å¤šå°‘å‘¢ï¼Ÿ\n\n"
            "è«‹ç›´æ¥è¼¸å…¥æ•¸å­—ï¼Œæˆ–é¸æ“‡ï¼š\n"
            "â€¢ è¼¸å…¥ã€Œ3000ã€ã€Œ5000ã€ã€Œ8000ã€ç­‰æ•¸å­—\n"
            "â€¢ æˆ–è¼¸å…¥ã€Œä¸é™ã€ã€Œéš¨ä¾¿ã€ä»£è¡¨æ²’æœ‰é ç®—é™åˆ¶"
        ),
        "location_pref": (
            "ğŸ“ è«‹å•æ‚¨å¸Œæœ›ä½åœ¨å“ªå€‹å€åŸŸå‘¢ï¼Ÿ\n\n" 
            "1ï¸âƒ£ é è¿‘å¸‚å€ - ç”Ÿæ´»æ©Ÿèƒ½å¥½ã€åƒé£¯è³¼ç‰©æ–¹ä¾¿\n"
            "2ï¸âƒ£ é è¿‘å­¸æ ¡ - é€šå‹¤æ–¹ä¾¿ã€ä¸Šèª²ä¸é²åˆ°\n"
            "3ï¸âƒ£ å®‰éœååƒ» - ç’°å¢ƒæ¸…å¹½ã€ç§Ÿé‡‘è¼ƒä¾¿å®œ\n\n"
            "è«‹è¼¸å…¥ 1ã€2ã€3 æˆ–ç›´æ¥æè¿°æ‚¨çš„åå¥½ï½"
        ),
        "type_pref": (
            "ğŸ  è«‹å•æ‚¨åå¥½å“ªç¨® æˆ¿å‹ å‘¢ï¼Ÿ\n\n"
            "1ï¸âƒ£ å¥—æˆ¿ - ç¨ç«‹è¡›æµ´ã€éš±ç§æ€§é«˜\n"
            "2ï¸âƒ£ é›…æˆ¿ - å…±ç”¨è¡›æµ´ã€ç§Ÿé‡‘è¼ƒä½\n"
            "3ï¸âƒ£ æ•´å±¤å…¬å¯“ - è·Ÿæœ‹å‹åˆç§Ÿã€ç©ºé–“å¤§\n\n"
            "è«‹è¼¸å…¥ 1ã€2ã€3 æˆ–ç›´æ¥æè¿°ï½"
        ),
        "management_pref": (
            "ğŸ‘¤ é—œæ–¼ æˆ¿æ±ç®¡ç†æ–¹å¼ï¼Œæ‚¨æœ‰ä»€éº¼åå¥½å—ï¼Ÿ\n\n"
            "1ï¸âƒ£ æˆ¿æ±åŒä½ - æœ‰å•é¡Œå¯ä»¥ç›´æ¥æ‰¾äºº\n"
            "2ï¸âƒ£ å°ˆæ¥­ç®¡ç† - ç®¡ç†å…¬å¸è™•ç†ï¼Œè¼ƒæœ‰ä¿éšœ\n"
            "3ï¸âƒ£ æˆ¿æ±ä¸ä½ - è‡ªç”±åº¦é«˜ï¼Œä¸å—æ‰“æ“¾\n"
            "4ï¸âƒ£ éƒ½å¯ä»¥ - æ²’æœ‰ç‰¹åˆ¥åå¥½\n\n"
            "è«‹è¼¸å…¥ 1ã€2ã€3ã€4 æˆ–ç›´æ¥æè¿°ï½"
        ),
        "features_preference": (
            "ğŸ”§ æœ€å¾Œï¼Œæœ‰æ²’æœ‰ä»€éº¼ å¿…å‚™è¨­æ–½ æ˜¯æ‚¨ä¸€å®šè¦æœ‰çš„ï¼Ÿ\n\n"
            "å¯ä»¥å¤šé¸ï¼Œä¾‹å¦‚ï¼š\n"
            "â€¢ å­æ¯è»Šï¼ˆåƒåœ¾ä»£æ”¶ï¼‰\n"
            "â€¢ é›»æ¢¯\n"
            "â€¢ é–€ç¦/ç›£è¦–å™¨\n"
            "â€¢ æ©Ÿè»Šåœè»Šä½\n"
            "â€¢ é™½å°\n\n"
            "è«‹åˆ—å‡ºæ‚¨åœ¨æ„çš„è¨­æ–½ï¼Œè‹¥æ²’æœ‰ç‰¹åˆ¥éœ€æ±‚è«‹è¼¸å…¥ã€Œéƒ½å¯ä»¥ã€ï¼"
        )
    }
    
    def __init__(self):
        self.base_url = config.OLLAMA_BASE_URL
        self.model_4b = config.OLLAMA_MODEL_4B
        # Stage 2 æ”¹ç”±ç¨‹å¼é‚è¼¯è™•ç†ï¼Œä¸å†éœ€è¦ model_1b
    
    def _call_ollama(self, model: str, prompt: str, system: str = None) -> str:
        """
        èª¿ç”¨ Ollama API
        
        Args:
            model: æ¨¡å‹åç¨±
            prompt: ä½¿ç”¨è€…è¼¸å…¥
            system: ç³»çµ±æç¤ºè©
            
        Returns:
            str: æ¨¡å‹å›æ‡‰
        """
        url = f"{self.base_url}/api/generate"
        
        payload = {
            "model": model,
            "prompt": prompt,
            "stream": False
        }
        
        if system:
            payload["system"] = system
        
        try:
            response = requests.post(url, json=payload, timeout=30)
            response.raise_for_status()
            result = response.json()
            return result.get("response", "")
        except requests.exceptions.RequestException as e:
            print(f"âŒ Ollama API éŒ¯èª¤: {e}")
            return ""
    
    def _get_extraction_prompt(self, topic: str = None) -> str:
        """å–å¾—æå–åƒæ•¸çš„ç³»çµ±æç¤ºè© (Stage 1: æœ¬åœ°AIæ¨¡å‹)"""
        base_prompt = """ä½ æ˜¯ä¸€å€‹è³‡æ–™æå–å“¡ï¼Œæœå‹™å°è±¡æ˜¯å¤§å­¸ç”Ÿç§Ÿå±‹æ—ç¾¤ã€‚
è«‹åˆ†æä½¿ç”¨è€…çš„è¼¸å…¥ï¼Œç”¨èªæ„ç†è§£å°‡å…¶è½‰æ›ç‚º JSON æ ¼å¼ã€‚
è«‹åªè¼¸å‡º JSONï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡‹æ€§æ–‡å­—æˆ– markdown æ¨™è¨˜ã€‚
ã€é‡è¦ã€‘ä½ å¿…é ˆä½¿ç”¨ç¹é«”ä¸­æ–‡å›ç­”ï¼Œç¦æ­¢ä½¿ç”¨ç°¡é«”ä¸­æ–‡ã€‚

éœ€è¦æå–çš„æ¬„ä½ï¼ˆè«‹ç”¨èªæ„ç†è§£æ­¸é¡ï¼‰ï¼š

ğŸ“ budget (æ•´æ•¸): æœˆç§Ÿé ç®—ä¸Šé™ï¼ˆæ–°å°å¹£ï¼‰
   - åˆ¤æ–·ä½¿ç”¨è€…èƒ½æ¥å—çš„æœ€é«˜æœˆç§Ÿé‡‘é¡
   - è‹¥èªªã€Œä¾¿å®œ/çœéŒ¢/çª®å­¸ç”Ÿã€â†’ ç´„ 3500
   - è‹¥èªªã€Œä¸€èˆ¬/æ™®é€š/ä¸­ç­‰ã€â†’ ç´„ 5500
   - è‹¥èªªã€Œä¸é™/éš¨ä¾¿/é ç®—å¤ ã€â†’ 99999
   - è‹¥èªªå…·é«”é‡‘é¡å¦‚ã€Œäº”åƒã€ã€Œ5000ã€â†’ ç›´æ¥ä½¿ç”¨è©²æ•¸å­—

ğŸ“ location_pref (å­—ä¸²): åœ°é»åå¥½ï¼Œæ­¸é¡åˆ°ä»¥ä¸‹ä¸‰ç¨®ä¹‹ä¸€ï¼š
   * "downtown" = ç”Ÿæ´»æ©Ÿèƒ½å¥½ã€è³¼ç‰©æ–¹ä¾¿ã€ç†±é¬§
     ï¼ˆä¾‹ï¼šå¸‚å€ã€èœå¸‚å ´ã€å¤œå¸‚ã€è¶…å•†å¤šã€åƒé£¯æ–¹ä¾¿ã€ä¾¿åˆ©ï¼‰
   * "school" = é è¿‘å­¸æ ¡ã€é€šå‹¤æ–¹ä¾¿
     ï¼ˆä¾‹ï¼šå­¸æ ¡é™„è¿‘ã€æš¨å¤§ã€æ ¡é–€å£ã€èµ°è·¯ä¸Šèª²ã€è¿‘ä¸€é»ï¼‰
   * "quiet" = ç’°å¢ƒæ¸…å¹½ã€å®‰éœã€ååƒ»
     ï¼ˆä¾‹ï¼šå®‰éœã€ååƒ»ã€äººå°‘ã€ä¾¿å®œçš„åœ°æ–¹ã€æ¸…å¹½ï¼‰

ğŸ“ type_pref (å­—ä¸²): æˆ¿å‹åå¥½ï¼Œæ­¸é¡åˆ°ä»¥ä¸‹ä¸‰ç¨®ä¹‹ä¸€ï¼š
   * "å¥—æˆ¿" = ç¨ç«‹ç©ºé–“ã€æœ‰è¡›æµ´ã€éš±ç§é«˜ã€ä¸€å€‹äººä½
     ï¼ˆä¾‹ï¼šå¥—æˆ¿ã€ç¨ç«‹è¡›æµ´ã€è‡ªå·±ä½ã€ä¸æƒ³å…±ç”¨å»æ‰€ï¼‰
   * "é›…æˆ¿" = å…±ç”¨è¡›æµ´ã€åƒ¹æ ¼è¼ƒä½ã€å¯æ¥å—å®¤å‹
     ï¼ˆä¾‹ï¼šé›…æˆ¿ã€ä¾¿å®œã€å…±ç”¨è¡›æµ´ã€çœéŒ¢ï¼‰
   * "æ•´å±¤" = æ•´å±¤å…¬å¯“ã€èˆ‡æœ‹å‹åˆç§Ÿã€ç©ºé–“å¤§
     ï¼ˆä¾‹ï¼šæ•´å±¤ã€å…¬å¯“ã€åˆç§Ÿã€è·Ÿæœ‹å‹ä¸€èµ·ã€ä¸‰æˆ¿ï¼‰

ğŸ“ management_pref (å­—ä¸²): æˆ¿æ±ç®¡ç†åå¥½ï¼Œæ­¸é¡åˆ°ä»¥ä¸‹å››ç¨®ä¹‹ä¸€ï¼š
   * "owner" = æˆ¿æ±åŒä½ï¼Œæ–¹ä¾¿æ‰¾äººè™•ç†å•é¡Œ
     ï¼ˆä¾‹ï¼šæˆ¿æ±ä½ã€æœ‰äººç®¡ã€æ–¹ä¾¿ä¿®ç¹•ï¼‰
   * "pro" = å°ˆæ¥­ç®¡ç†å…¬å¸ï¼Œæœ‰ä¿éšœ
     ï¼ˆä¾‹ï¼šç®¡ç†å…¬å¸ã€å°ˆæ¥­ã€æœ‰åˆ¶åº¦ï¼‰
   * "no_owner" = æˆ¿æ±ä¸ä½ï¼Œè‡ªç”±åº¦é«˜
     ï¼ˆä¾‹ï¼šæˆ¿æ±ä¸ä½ã€è‡ªç”±ã€ä¸è¢«æ‰“æ“¾ã€ç¨ç«‹ï¼‰
   * "none" = æ²’æœ‰åå¥½ã€éƒ½å¯ä»¥
     ï¼ˆä¾‹ï¼šéƒ½å¯ä»¥ã€æ²’å·®ã€éš¨ä¾¿ã€ç„¡æ‰€è¬‚ï¼‰

ğŸ“ features_preference (å­—ä¸²): è¨­æ–½éœ€æ±‚å›ç­”ç‹€æ…‹
   - ç•¶ä½¿ç”¨è€…å®Œæˆè¨­æ–½éœ€æ±‚å›ç­”æ™‚ï¼ˆèªªäº†å…·é«”è¨­æ–½æˆ–èªªã€Œéƒ½å¯ä»¥ã€ï¼‰â†’ å¡«å…¥ "done"

ğŸ“ required_features (å­—ä¸²é™£åˆ—): ä½¿ç”¨è€…æåˆ°çš„è¨­æ–½éœ€æ±‚
   - ä¾‹å¦‚ ["æ´—è¡£æ©Ÿ", "å†·æ°£", "é›»æ¢¯"]
   - å¸¸è¦‹è¨­æ–½ï¼šæ´—è¡£æ©Ÿã€å†·æ°£ã€å†°ç®±ã€ç†±æ°´å™¨ã€é›»æ¢¯ã€å­æ¯è»Š(åƒåœ¾ä»£æ”¶)ã€
     é–€ç¦ã€ç›£è¦–å™¨ã€è»Šä½ã€é™½å°ã€å°å¤–çª—ã€ç¶²è·¯/WiFiã€å‚¢ä¿±ã€åºŠã€è¡£æ«ƒã€æ›¸æ¡Œ

è¦å‰‡ï¼š
1. åªæå–ä½¿ç”¨è€…æ˜ç¢ºæåˆ°çš„è³‡è¨Šï¼Œæ²’æåˆ°çš„æ¬„ä½ä¸è¦è¼¸å‡º
2. ç”¨èªæ„ç†è§£åˆ¤æ–·ä½¿ç”¨è€…æ„åœ–ï¼Œä¸è¦æ­»æ¿å°ç…§é—œéµå­—
3. è‹¥ç„¡æ³•åˆ¤æ–·å±¬æ–¼å“ªä¸€é¡ï¼Œå¯§å¯ä¸è¼¸å‡ºè©²æ¬„ä½"""

        if topic == "management_pref":
             base_prompt += '\n5. ç•¶å‰æ­£åœ¨è©¢å•ã€Œç®¡ç†åå¥½ã€ï¼Œè‹¥ä½¿ç”¨è€…å›ç­”ã€Œéš¨ä¾¿/éƒ½å¯ä»¥/æ²’å·®ã€ï¼Œè«‹è¼¸å‡º {"management_pref": "none"}'
        elif topic == "features_preference":
             base_prompt += '\n5. ç•¶å‰æ­£åœ¨è©¢å•ã€Œè¨­æ–½éœ€æ±‚ã€ï¼Œè‹¥ä½¿ç”¨è€…å›ç­”ã€Œéš¨ä¾¿/éƒ½å¯ä»¥/æ²’å·®ã€ï¼Œè«‹è¼¸å‡º {"features_preference": "done"}'
        elif topic == "budget":
             base_prompt += '\n5. ç•¶å‰æ­£åœ¨è©¢å•ã€Œé ç®—ã€ï¼Œè‹¥ä½¿ç”¨è€…å›ç­”ã€Œéš¨ä¾¿/ä¸é™ã€ï¼Œè«‹è¼¸å‡º {"budget": 99999}'
        elif topic == "type_pref":
             base_prompt += '\n5. ç•¶å‰æ­£åœ¨è©¢å•ã€Œæˆ¿å‹ã€ï¼Œè‹¥ä½¿ç”¨è€…å›ç­”ã€Œä¸€å€‹äººä½/å–®äºº/ç¨å±…ã€ï¼Œè«‹å‚¾å‘è¼¸å‡º {"type_pref": "å¥—æˆ¿"}'

        # æ ¹æ“šä¸åŒä¸»é¡Œæä¾›å°æ‡‰çš„ç¯„ä¾‹ï¼Œé¿å… AI æ··æ·†
        if topic == "budget":
            base_prompt += '\n\nè¼¸å‡ºç¯„ä¾‹ï¼š\n{"budget": 5000}'
        elif topic == "location_pref":
            base_prompt += '\n\nè¼¸å‡ºç¯„ä¾‹ï¼š\n{"location_pref": "downtown"}'
        elif topic == "type_pref":
             base_prompt += '\n\nè¼¸å‡ºç¯„ä¾‹ï¼š\n{"type_pref": "å¥—æˆ¿"}'
        elif topic == "management_pref":
             base_prompt += '\n\nè¼¸å‡ºç¯„ä¾‹ï¼š\n{"management_pref": "no_owner"}'
        elif topic == "features_preference":
             base_prompt += '\n\nè¼¸å‡ºç¯„ä¾‹ï¼š\n{"required_features": ["æ´—è¡£æ©Ÿ", "é™½å°"], "features_preference": "done"}'
        else:
             base_prompt += '\n\nè¼¸å‡ºç¯„ä¾‹ï¼š\n{"budget": 5000}'
             
        return base_prompt
    
    def extract_params(self, user_input: str, topic: str = None) -> dict:
        """
        Stage 1: å¾ä½¿ç”¨è€…è¼¸å…¥æå–åƒæ•¸
        
        Args:
            user_input: ä½¿ç”¨è€…çš„è‡ªç„¶èªè¨€è¼¸å…¥
            topic: ç•¶å‰æ­£åœ¨è©¢å•çš„ä¸»é¡Œ (ä¸Šä¸‹æ–‡)
            
        Returns:
            dict: æå–å‡ºçš„åƒæ•¸
        """
        system_prompt = self._get_extraction_prompt(topic)
        
        response = self._call_ollama(
            model=self.model_4b,
            prompt=user_input,
            system=system_prompt
        )
        
        # å˜—è©¦è§£æ JSON
        try:
            # æ¸…ç†å¯èƒ½çš„ markdown æ¨™è¨˜
            response = response.strip()
            
            # æ¸…ç† <think> æ¨™ç±¤ (é‡å°æ€è€ƒå‹æ¨¡å‹)
            import re
            response = re.sub(r'<think>.*?</think>', '', response, flags=re.DOTALL).strip()
            
            if response.startswith("```"):
                lines = response.split("\n")
                # å°‹æ‰¾ JSON å€å¡Š
                json_lines = []
                in_json = False
                for line in lines:
                    if line.strip().startswith("```"):
                        if in_json: break
                        else: in_json = True; continue
                    if in_json:
                        json_lines.append(line)
                
                if json_lines:
                    response = "\n".join(json_lines)
                else:
                    # Fallback: å¦‚æœæ²’æœ‰å®Œæ•´åŒ…è¦†ï¼Œå˜—è©¦å»æ‰ç¬¬ä¸€è¡Œå’Œæœ€å¾Œä¸€è¡Œ
                    response = "\n".join(lines[1:-1])
            
            # æœ‰æ™‚å€™æ¨¡å‹æœƒè¼¸å‡º JSON ä»¥å¤–çš„å»¢è©±ï¼Œå˜—è©¦åªæŠ“å–ç¬¬ä¸€å€‹ { åˆ°æœ€å¾Œä¸€å€‹ }
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                response = json_match.group(0)
            
            return json.loads(response)
        except (json.JSONDecodeError, Exception) as e:
            print(f"âš ï¸ JSON è§£æå¤±æ•—: {response} (Error: {e})")
            return {}
    
    def check_completeness(self, collected_data: dict) -> tuple[bool, list[str]]:
        """
        ç”¨ç¨‹å¼é‚è¼¯æª¢æŸ¥è³‡æ–™å®Œæ•´æ€§ (ä¸ä¾è³´ AI)
        
        Args:
            collected_data: ç›®å‰å·²æ”¶é›†çš„è³‡æ–™
            
        Returns:
            tuple[bool, list[str]]: (æ˜¯å¦å®Œæˆ, ç¼ºå°‘çš„æ¬„ä½åˆ—è¡¨)
        """
        missing = []
        for field in self.REQUIRED_FIELDS:
            if field not in collected_data or collected_data[field] is None:
                missing.append(field)
        
        return len(missing) == 0, missing
    
    def generate_follow_up_question(self, missing_fields: list[str]) -> str:
        """
        æ ¹æ“šç¼ºå°‘çš„æ¬„ä½ç”Ÿæˆè¿½å•å•é¡Œ (ä½¿ç”¨é è¨­å•é¡Œåº«)
        
        Args:
            missing_fields: ç¼ºå°‘çš„æ¬„ä½åˆ—è¡¨
            
        Returns:
            str: è¿½å•å•é¡Œ
        """
        if missing_fields:
            first_missing = missing_fields[0]
            return self.QUESTIONS.get(first_missing, f"è«‹å•æ‚¨å° {first_missing} æœ‰ä»€éº¼åå¥½å—ï¼Ÿ")
        
        return "è«‹å‘Šè¨´æˆ‘æ›´å¤šæ‚¨çš„éœ€æ±‚ï½"
    
    def check_and_respond(self, collected_data: dict) -> tuple[bool, str]:
        """
        Stage 2: æª¢æŸ¥è³‡æ–™å®Œæ•´æ€§ä¸¦ç”Ÿæˆå›æ‡‰ (æ”¹ç”¨ç¨‹å¼é‚è¼¯)
        
        Args:
            collected_data: ç›®å‰å·²æ”¶é›†çš„è³‡æ–™
            
        Returns:
            tuple[bool, str]: (æ˜¯å¦å®Œæˆ, è¿½å•èªå¥æˆ–ç¢ºèªè¨Šæ¯)
        """
        is_complete, missing = self.check_completeness(collected_data)
        
        if is_complete:
            return True, "å¥½çš„ï¼æˆ‘å·²ç¶“äº†è§£æ‚¨çš„éœ€æ±‚äº†ã€‚è«‹è¼¸å…¥ ã€é–‹å§‹åˆ†æã€ ä¾†æŸ¥çœ‹æ‚¨çš„å°ˆå±¬ç§Ÿå±‹äººæ ¼è¨ºæ–·ã€‚"
        else:
            return False, self.generate_follow_up_question(missing)
    
    def analyze_and_respond(self, user_input: str, collected_data: dict, user_id: str = None) -> dict:
        """
        å®Œæ•´çš„åˆ†ææµç¨‹ (Stage 1 ç”¨ AI æå–ï¼ŒStage 2 ç”¨ç¨‹å¼åˆ¤æ–·)
        
        Args:
            user_input: ä½¿ç”¨è€…è¼¸å…¥
            collected_data: ç›®å‰å·²æ”¶é›†çš„è³‡æ–™
            user_id: ä½¿ç”¨è€… ID (ç”¨æ–¼å„²å­˜ AI ç´€éŒ„)
            
        Returns:
            dict: {
                "collected_data": æ›´æ–°å¾Œçš„è³‡æ–™,
                "is_complete": æ˜¯å¦å®Œæˆè³‡æ–™æ”¶é›†,
                "response": è¦å›è¦†çµ¦ä½¿ç”¨è€…çš„è¨Šæ¯
            }
        """
        # 0. åˆ¤æ–·ç•¶å‰ä¸Šä¸‹æ–‡ (æ­£åœ¨å•å“ªä¸€é¡Œ)
        # ç”¨ç¨‹å¼é‚è¼¯é åˆ¤ç¼ºå°‘çš„æ¬„ä½ï¼Œæ‰¾å‡ºç¬¬ä¸€å€‹ç¼ºå¤±é …ä½œç‚º context
        _, missing_before = self.check_completeness(collected_data)
        current_topic = missing_before[0] if missing_before else None
        print(f"ğŸ§  ç•¶å‰ä¸Šä¸‹æ–‡æ¨æ–·: {current_topic}")

        # Stage 1: æå–åƒæ•¸ (å¸¶å…¥ä¸Šä¸‹æ–‡)
        extracted = self.extract_params(user_input, topic=current_topic)
        print(f"ğŸ” AI æå–çµæœ: {extracted}")
        
        # ç”¨æ–¼ç´€éŒ„çš„è®Šæ•¸
        ai_raw_response = str(extracted) if extracted else ""
        is_success = bool(extracted)
        
        # å¦‚æœ AI æ²’æå–åˆ°æ±è¥¿ï¼Œå˜—è©¦ç”¨ç°¡å–®è¦å‰‡è§£æ
        if not extracted:
            extracted = self._simple_parse(user_input, topic=current_topic)
            print(f"ğŸ“ ç°¡å–®è§£æçµæœ: {extracted}")
            if extracted:
                ai_raw_response = f"[è¦å‰‡è§£æ] {extracted}"
                is_success = True
        
        # åˆä½µå·²æ”¶é›†çš„è³‡æ–™
        merged_data = {**collected_data, **extracted}
        print(f"ğŸ“¦ åˆä½µå¾Œè³‡æ–™: {merged_data}")
        
        # åˆ¤æ–·æ˜¯å¦æˆåŠŸæå–åˆ°è³‡æ–™
        if extracted:
            # æˆåŠŸæå–ï¼šèµ°æ¨™æº–æµç¨‹ (æª¢æŸ¥è³‡æ–™å®Œæ•´æ€§ -> ä¸‹ä¸€é¡Œ)
            is_complete, response = self.check_and_respond(merged_data)
        else:
            # æå–å¤±æ•— (ä¾‹å¤–ç‹€æ³)ï¼šè«‹ AI é‡å°ä½¿ç”¨è€…çš„å›ç­”çµ¦äºˆå¼•å°
            print(f"âš ï¸ æå–å¤±æ•—ï¼Œå•Ÿå‹• AI å¼•å°æ¨¡å¼ (Topic: {current_topic})")
            is_complete = False
            response = self.generate_guidance(user_input, current_topic)
            ai_raw_response = f"[å¼•å°] {response}"
        
        # å„²å­˜ AI ç´€éŒ„
        if user_id:
            self._save_ai_log(
                user_id=user_id,
                topic=current_topic,
                user_input=user_input,
                ai_raw_response=ai_raw_response,
                extracted_data=extracted,
                is_success=is_success
            )
        
        return {
            "collected_data": merged_data,
            "is_complete": is_complete,
            "response": response
        }
    
    def _save_ai_log(self, user_id: str, topic: str, user_input: str, 
                     ai_raw_response: str, extracted_data: dict, is_success: bool) -> None:
        """
        å„²å­˜ AI æ€è€ƒç´€éŒ„
        """
        try:
            from app.models import db_session
            from app.models.ai_log import AILog
            
            log = AILog(
                user_id=user_id,
                topic=topic,
                user_input=user_input,
                ai_raw_response=ai_raw_response,
                extracted_data=extracted_data or {},
                is_success=is_success
            )
            db_session.add(log)
            db_session.commit()
            print(f"ğŸ“ å·²å„²å­˜ AI ç´€éŒ„: user={user_id[:8]}... topic={topic}")
        except Exception as e:
            print(f"âš ï¸ å„²å­˜ AI ç´€éŒ„å¤±æ•—: {e}")
    
    def generate_guidance(self, user_input: str, topic: str) -> str:
        """
        ç•¶ä½¿ç”¨è€…å›ç­”ç„¡æ³•è¢«è§£ææ™‚ï¼Œç”Ÿæˆå¼•å°èªå¥
        
        Args:
            user_input: ä½¿ç”¨è€…è¼¸å…¥
            topic: ç•¶å‰ä¸»é¡Œ
            
        Returns:
            str: å¼•å°èªå¥
        """
        topic_name = {
            "budget": "é ç®—ç¯„åœ",
            "location_pref": "åœ°é»åå¥½",
            "type_pref": "æˆ¿å‹åå¥½",
            "management_pref": "ç®¡ç†æ–¹å¼",
            "features_preference": "è¨­æ–½éœ€æ±‚"
        }.get(topic, "ç§Ÿå±‹éœ€æ±‚")
        
        # å–å¾—åŸé¡Œç›®å…§å®¹ä¾› AI å°ç…§
        original_question = self.QUESTIONS.get(topic, "")
        
        system_prompt = f"""ä½ æ˜¯ Chi Sooï¼Œä¸€å€‹è¦ªåˆ‡çš„å°ˆé–€æœå‹™å°ç£å—æŠ•ç¸£åŸ”é‡Œé®æš¨å—å¤§å­¸ç”Ÿçš„ç§Ÿå±‹é¡§å•æ©Ÿå™¨äºº ğŸ¦”

ã€èƒŒæ™¯ã€‘
- ä½ æ­£åœ¨å¹«åŠ©ã€Œå¤§å­¸ç”Ÿã€å°‹æ‰¾å­¸æ ¡é™„è¿‘çš„ã€Œç§Ÿå±‹ã€ï¼ˆä¸æ˜¯è²·æˆ¿ï¼ï¼‰
- ä½¿ç”¨è€…å¤§å¤šæ˜¯å¹´è¼•æ—ç¾¤ï¼Œèªæ°£å¯ä»¥è¼•é¬†æ´»æ½‘ã€åƒå­¸é•·å§ä¸€æ¨£è¦ªåˆ‡
- ç›®æ¨™æ˜¯æ”¶é›†ç§Ÿå±‹éœ€æ±‚è³‡è¨Šï¼Œå¹«ä»–å€‘æ‰¾åˆ°é©åˆçš„æˆ¿æº

ã€ç•¶å‰æƒ…å¢ƒã€‘
æ­£åœ¨è©¢å•ä½¿ç”¨è€…çš„ã€Œ{topic_name}ã€ã€‚

åŸæœ¬çš„é¡Œç›®æ˜¯ï¼š
---
{original_question}
---

ä½¿ç”¨è€…å›ç­”äº†ï¼šã€Œ{user_input}ã€
ä½†é€™å€‹å›ç­”ç„¡æ³•è¢«æ­£ç¢ºè§£æï¼ˆå¯èƒ½ç­”éæ‰€å•ã€æˆ–æ ¼å¼ä¸å°ï¼‰ã€‚

ã€ä»»å‹™ã€‘
ç”Ÿæˆä¸€å¥è©± (15 å­—ä»¥å…§) å¼•å°ä½¿ç”¨è€…é‡æ–°ä½œç­”ï¼š
- å‘ŠçŸ¥å›ç­”åé¡Œäº†ï¼Œè«‹ç”¨æˆ¶è¦æ ¹æ“šé¡Œç›®å†å›ç­”ä¸€æ¬¡
- èªæ°£è¼•é¬†è‡ªç„¶ï¼Œåƒæœ‹å‹èŠå¤©

ã€é‡è¦ã€‘ä½¿ç”¨ç¹é«”ä¸­æ–‡ï¼Œç›´æ¥è¼¸å‡ºé‚£ä¸€å¥è©±ï¼Œä¸è¦æœ‰å¤šé¤˜æ–‡å­—ã€‚"""

        response = self._call_ollama(
            model=self.model_4b,
            prompt=user_input,
            system=system_prompt
        )
        
        # æ¸…ç†å›æ‡‰
        response = response.strip().replace('"', '')
        
        # å¦‚æœ AI å›æ‡‰å¤ªçŸ­æˆ–å¤±æ•—ï¼Œå›é€€åˆ°é è¨­å•é¡Œ
        if len(response) < 5:
            return self.QUESTIONS.get(topic, "ä¸å¥½æ„æ€ï¼Œå¯ä»¥è«‹æ‚¨å†èªªæ˜ä¸€æ¬¡å—ï¼Ÿ")
            
        return response
    
    def _simple_parse(self, user_input: str, topic: str = None) -> dict:
        """
        ç°¡å–®è¦å‰‡è§£æ (ç•¶ AI å¤±æ•—æ™‚çš„å‚™ç”¨æ–¹æ¡ˆ)
        """
        result = {}
        text = user_input.lower()
        
        # è§£æé ç®— (å„ªå…ˆåˆ¤æ–·æ˜¯å¦ç‚ºæ•¸å­—ä¸”æ•¸å€¼è¼ƒå¤§)
        import re
        budget_match = re.search(r'(\d{3,5})', user_input)
        if budget_match:
            result["budget"] = int(budget_match.group(1))
        elif "ä¾¿å®œ" in text or "çœ" in text:
            result["budget"] = 3500
        elif "ä¸é™" in text or "ç„¡ä¸Šé™" in text or "æ²’æœ‰ä¸Šé™" in text:
            result["budget"] = 99999
        elif "éš¨ä¾¿" in text and ("é ç®—" in text or topic == "budget"):
            result["budget"] = 99999
        
        # è§£æåœ°é»
        if "å¸‚å€" in text or "æ–¹ä¾¿" in text or "1" in text:
            result["location_pref"] = "downtown"
        elif "å­¸æ ¡" in text or "æš¨å¤§" in text or "2" in text:
            result["location_pref"] = "school"
        elif "å®‰éœ" in text or "ååƒ»" in text or "3" in text:
            result["location_pref"] = "quiet"
        elif "éš¨ä¾¿" in text and ("åœ°é»" in text or topic == "location_pref"):
            result["location_pref"] = "school" # éš¨ä¾¿çš„è©±é è¨­çµ¦å­¸æ ¡(æ–¹ä¾¿)
        
        # è§£ææˆ¿å‹åå¥½
        if "å¥—æˆ¿" in text or user_input.strip() == "1":
            result["type_pref"] = "å¥—æˆ¿"
        elif "é›…æˆ¿" in text or user_input.strip() == "2":
            result["type_pref"] = "é›…æˆ¿"
        elif "æ•´å±¤" in text or "å…¬å¯“" in text or "åˆç§Ÿ" in text or user_input.strip() == "3":
            result["type_pref"] = "æ•´å±¤"
        elif "éš¨ä¾¿" in text and ("æˆ¿å‹" in text or topic == "type_pref"):
            result["type_pref"] = "å¥—æˆ¿" # é è¨­
        
        # è§£æç®¡ç†åå¥½
        if "æˆ¿æ±åŒä½" in text or "åŒä½" in text or user_input.strip() == "1":
            result["management_pref"] = "owner"
        elif "å°ˆæ¥­ç®¡ç†" in text or "ç®¡ç†å…¬å¸" in text or user_input.strip() == "2":
            result["management_pref"] = "pro"
        elif "ä¸ä½" in text or "ä¸è¦ä½" in text or "è‡ªç”±" in text or user_input.strip() == "3":
            result["management_pref"] = "no_owner"
        elif ("éƒ½å¯" in text or "ç„¡æ‰€è¬‚" in text or "æ²’å·®" in text or user_input.strip() == "4" or "éš¨ä¾¿" in text) and \
             ("ç®¡ç†" in text or topic == "management_pref"):
            result["management_pref"] = "none"
        
        # è§£æè¨­æ–½éœ€æ±‚ (æ”¹ç”¨è‡ªç”±æ–‡å­—é™£åˆ—)
        feature_keywords = {
            "æ´—è¡£æ©Ÿ": ["æ´—è¡£", "æ´—è¡£æ©Ÿ"],
            "å†·æ°£": ["å†·æ°£", "ç©ºèª¿", "å†·æ°£æ©Ÿ"],
            "å†°ç®±": ["å†°ç®±"],
            "ç†±æ°´å™¨": ["ç†±æ°´å™¨", "ç†±æ°´"],
            "é›»æ¢¯": ["é›»æ¢¯"],
            "å­æ¯è»Š": ["å­æ¯è»Š", "åƒåœ¾", "ä»£æ”¶"],
            "é–€ç¦": ["é–€ç¦", "åˆ·å¡"],
            "ç›£è¦–å™¨": ["ç›£è¦–", "ç›£æ§", "æ”å½±"],
            "è»Šä½": ["åœè»Š", "è»Šä½", "æ©Ÿè»Š"],
            "é™½å°": ["é™½å°", "æ›¬è¡£"],
            "å°å¤–çª—": ["å°å¤–çª—", "çª—æˆ¶", "æ¡å…‰"],
            "ç¶²è·¯": ["ç¶²è·¯", "wifi", "wi-fi"],
            "å‚¢ä¿±": ["å‚¢ä¿±", "å®¶å…·"],
            "åºŠ": ["åºŠ"],
            "è¡£æ«ƒ": ["è¡£æ«ƒ", "è¡£æ«¥"],
            "æ›¸æ¡Œ": ["æ›¸æ¡Œ", "æ¡Œå­"],
        }
        
        found_features = []
        for feature_name, keywords in feature_keywords.items():
            for keyword in keywords:
                if keyword in text:
                    found_features.append(feature_name)
                    break
        
        if found_features:
            result["required_features"] = found_features
            result["features_preference"] = "done"
        
        # è‹¥æ­£åœ¨å•è¨­æ–½ä¸”å›ç­”éš¨ä¾¿/éƒ½å¯ä»¥ï¼Œä¹Ÿæ¨™è¨˜å®Œæˆ
        is_generic_reply = "éƒ½å¯" in text or "æ²’å·®" in text or "ç„¡æ‰€è¬‚" in text or "æ²’æœ‰" in text or "éš¨ä¾¿" in text
        
        # å·²åœ¨ä¸Šæ–¹è™•ç† found_featuresï¼Œé€™è£¡åªè™•ç†ã€Œéƒ½å¯ä»¥ã€çš„æƒ…æ³
        if is_generic_reply and topic == "features_preference" and "features_preference" not in result:
            result["features_preference"] = "done"
        
        return result
    
    def test_connection(self) -> bool:
        """
        æ¸¬è©¦ Ollama é€£ç·š
        
        Returns:
            bool: æ˜¯å¦é€£ç·šæˆåŠŸ
        """
        try:
            response = requests.get(f"{self.base_url}/api/tags", timeout=5)
            return response.status_code == 200
        except requests.exceptions.RequestException:
            return False
    
    def list_models(self) -> list[str]:
        """
        åˆ—å‡ºå¯ç”¨çš„æ¨¡å‹
        
        Returns:
            list[str]: æ¨¡å‹åç¨±åˆ—è¡¨
        """
        try:
            response = requests.get(f"{self.base_url}/api/tags", timeout=5)
            response.raise_for_status()
            data = response.json()
            return [model["name"] for model in data.get("models", [])]
        except requests.exceptions.RequestException:
            return []
    
    def match_features_semantically(self, user_features: list[str], persona_features: list[str]) -> dict:
        """
        ä½¿ç”¨ AI é€²è¡Œèªæ„ç‰¹å¾µåŒ¹é… (å–®ä¸€ Persona)
        
        Args:
            user_features: ä½¿ç”¨è€…æƒ³è¦çš„è¨­æ–½åˆ—è¡¨
            persona_features: äººç‰©èªŒæä¾›çš„è¨­æ–½åˆ—è¡¨
            
        Returns:
            dict: {"matched": int, "total": int, "match_rate": float}
        """
        if not user_features:
            return {"matched": 0, "total": 0, "match_rate": 0.5}
        
        if not persona_features:
            return {"matched": 0, "total": len(user_features), "match_rate": 0.0}
        
        # ç°¡å–®å­—ä¸²åŒ…å«åŒ¹é… (Fallback é‚è¼¯ï¼Œå¿«é€Ÿ)
        matched = 0
        persona_str = " ".join(persona_features).lower()
        for feature in user_features:
            if feature.lower() in persona_str or any(f.lower() in feature.lower() for f in persona_features):
                matched += 1
        
        return {
            "matched": matched,
            "total": len(user_features),
            "match_rate": matched / len(user_features) if user_features else 0
        }
    
    def batch_match_features(self, user_features: list[str], all_personas_features: dict[str, list[str]]) -> dict[str, dict]:
        """
        ä½¿ç”¨ AI æ‰¹æ¬¡é€²è¡Œæ‰€æœ‰ Persona çš„èªæ„ç‰¹å¾µåŒ¹é… (å–®æ¬¡ API å‘¼å«)
        
        Args:
            user_features: ä½¿ç”¨è€…æƒ³è¦çš„è¨­æ–½åˆ—è¡¨ (å¦‚ ["æ´—è¡£æ©Ÿ", "é™½å°"])
            all_personas_features: æ‰€æœ‰äººç‰©èªŒçš„è¨­æ–½å­—å…¸ 
                {"type_A": ["washer", "elevator"], "type_B": ["wifi", "parking"], ...}
            
        Returns:
            dict: {"type_A": {"matched": 2, "total": 2, "match_rate": 1.0}, ...}
        """
        if not user_features:
            return {pid: {"matched": 0, "total": 0, "match_rate": 0.5} for pid in all_personas_features}
        
        # å»ºæ§‹æ‰¹æ¬¡æ¯”å°çš„æç¤ºè©
        personas_list_str = "\n".join([f"- {pid}: {features}" for pid, features in all_personas_features.items()])
        
        system_prompt = f"""ä½ æ˜¯ä¸€å€‹è¨­æ–½åŒ¹é…å°ˆå®¶ã€‚è«‹åˆ¤æ–·ä½¿ç”¨è€…æƒ³è¦çš„è¨­æ–½åœ¨æ¯å€‹ç§Ÿå±‹é¡å‹ä¸­æ˜¯å¦å­˜åœ¨ã€‚
ä½¿ç”¨èªæ„ç†è§£ä¾†åˆ¤æ–·ï¼Œä¾‹å¦‚ã€Œæ´—è¡£æ©Ÿã€æ‡‰è©²åŒ¹é…ã€Œwasherã€æˆ–ã€Œæ´—è¡£è¨­å‚™ã€ã€‚

ä½¿ç”¨è€…æƒ³è¦çš„è¨­æ–½: {user_features}

å„é¡å‹å¯æä¾›çš„è¨­æ–½:
{personas_list_str}

è«‹å›å‚³ä¸€å€‹ JSONï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
{{
  "é¡å‹ID": {{"matched_count": åŒ¹é…æ•¸é‡}},
  ...
}}

ä¾‹å¦‚ï¼š
{{
  "type_A": {{"matched_count": 2}},
  "type_B": {{"matched_count": 1}}
}}

ã€é‡è¦ã€‘åªè¼¸å‡º JSONï¼Œä¸è¦æœ‰å…¶ä»–æ–‡å­—ã€‚ä½¿ç”¨ç¹é«”ä¸­æ–‡æ€è€ƒä½†è¼¸å‡ºè‹±æ–‡ keyã€‚"""

        response = self._call_ollama(
            model=self.model_4b,
            prompt="è«‹é€²è¡Œæ‰¹æ¬¡è¨­æ–½åŒ¹é…åˆ†æ",
            system=system_prompt
        )
        
        try:
            import re
            response = response.strip()
            response = re.sub(r'<think>.*?</think>', '', response, flags=re.DOTALL).strip()
            
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                response = json_match.group(0)
            
            result = json.loads(response)
            
            # è½‰æ›æˆæ¨™æº–æ ¼å¼
            output = {}
            total = len(user_features)
            for pid in all_personas_features:
                matched = result.get(pid, {}).get("matched_count", 0)
                output[pid] = {
                    "matched": matched,
                    "total": total,
                    "match_rate": matched / total if total > 0 else 0
                }
            
            print(f"ğŸ”— AI æ‰¹æ¬¡è¨­æ–½åŒ¹é…å®Œæˆ")
            for pid, data in output.items():
                print(f"   {pid}: {data['matched']}/{data['total']} ({data['match_rate']*100:.0f}%)")
            
            return output
            
        except Exception as e:
            print(f"âš ï¸ AI æ‰¹æ¬¡è¨­æ–½åŒ¹é…è§£æå¤±æ•—: {e}")
            # Fallback: é€ä¸€ä½¿ç”¨ç°¡å–®åŒ¹é…
            return {pid: self.match_features_semantically(user_features, features) 
                    for pid, features in all_personas_features.items()}
